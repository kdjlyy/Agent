{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.固定长度文本切分\n",
    "\n",
    "按照固定的文本长度切分文本，不同分块之间可以有固定长度的重叠内容。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T15:20:30.845174Z",
     "start_time": "2025-05-08T15:20:30.839781Z"
    }
   },
   "source": [
    "def fixed_length_split(text: str, chunk_size: int, chunk_overlap: int = 0) -> list:\n",
    "    \"\"\"Split text into fixed length chunks with optional overlap.\"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# 测试数据\n",
    "text = \"\"\"文本分块（Text Chunking / Splitting），顾名思义，就是将原始的、可能非常庞大的文本资料\\\n",
    "（例如，一篇长篇报告、一本电子书、一个复杂的网页或者大量的 API 文档）分割成一系列更小、更易于处理的文本片段（Chunks）的过程。\\\n",
    "这些 Chunks 是 RAG 系统中信息处理的基本单元，它们将被送入 Embedding 模型进行向量化，然后存入向量数据库进行索引，最终服务于检索环节。\"\"\"\n",
    "chunk_size, chunk_overlap = 50, 10\n",
    "\n",
    "# 测试\n",
    "chunks = fixed_length_split(text, chunk_size, chunk_overlap)\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print('-'*30 + f' Chunk {idx} ' + '-'*30)\n",
    "    print(chunk)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Chunk 0 ------------------------------\n",
      "文本分块（Text Chunking / Splitting），顾名思义，就是将原始的、可能非常庞大\n",
      "------------------------------ Chunk 1 ------------------------------\n",
      "原始的、可能非常庞大的文本资料（例如，一篇长篇报告、一本电子书、一个复杂的网页或者大量的 API 文\n",
      "------------------------------ Chunk 2 ------------------------------\n",
      "者大量的 API 文档）分割成一系列更小、更易于处理的文本片段（Chunks）的过程。这些 Chun\n",
      "------------------------------ Chunk 3 ------------------------------\n",
      "过程。这些 Chunks 是 RAG 系统中信息处理的基本单元，它们将被送入 Embedding 模\n",
      "------------------------------ Chunk 4 ------------------------------\n",
      "mbedding 模型进行向量化，然后存入向量数据库进行索引，最终服务于检索环节。\n",
      "------------------------------ Chunk 5 ------------------------------\n",
      "。\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Markdown标题切分\n",
    "根据 Markdown 原生标题切分文本内容，将相同标题级别的文本片段切分在同一个 chunk 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Chunk 0 ------------------------------\n",
      "\n",
      "Main Header\n",
      "\n",
      "\n",
      "------------------------------ Chunk 1 ------------------------------\n",
      "Section 1\n",
      "Content for section 1\n",
      "\n",
      "\n",
      "------------------------------ Chunk 2 ------------------------------\n",
      "Subsection 1.1\n",
      "Subsection content\n",
      "\n",
      "\n",
      "------------------------------ Chunk 3 ------------------------------\n",
      "Section 2\n",
      "Another section\n",
      "\n",
      "Section 3\n",
      "test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def markdown_heading_split(text):\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    current_heading: str = None  # None, '#', '##', '###', etc.\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        match = re.match(r'^(#+)\\s*(.*)$', line)\n",
    "        if match:\n",
    "            heading, heading_text = match.groups()\n",
    "            if current_heading is None:\n",
    "                current_heading = heading\n",
    "            if heading == current_heading:\n",
    "                current_chunk += heading_text + '\\n'\n",
    "            else:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = heading_text + '\\n'\n",
    "                current_heading = heading\n",
    "        else:\n",
    "            current_chunk += line + '\\n'\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    return chunks\n",
    "\n",
    "# 测试数据\n",
    "text = \"\"\"\n",
    "# Main Header\n",
    "\n",
    "## Section 1\n",
    "Content for section 1\n",
    "\n",
    "### Subsection 1.1\n",
    "Subsection content\n",
    "\n",
    "## Section 2\n",
    "Another section\n",
    "\n",
    "## Section 3\n",
    "test\n",
    "\"\"\"\n",
    "\n",
    "# 测试\n",
    "chunks = markdown_heading_split(text)\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print('-'*30 + f' Chunk {idx} ' + '-'*30)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 递归文本切分\n",
    "按照字符递归切分，递归分块使用一组分隔符以分层和迭代的方式将输入文本分成更小的块\n",
    "\n",
    "Q: 为什么使用了 `RecursiveCharacterTextSplitter`，但是指定的 `chunk_overlap` 没有生效？  \n",
    "A：因为 `RecursiveCharacterTextSplitter` 会按照字符列表的优先级递归切分，当不能再切分下去并且 `chunk` 长度还是大于 `chunk_size` 时，才会使用 `chunk_overlap`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Chunk 0 ------------------------------\n",
      "文本分块（Text Chunking / Splitting）是什么？\n",
      "------------------------------ Chunk 1 ------------------------------\n",
      "顾名思义，就是将原始的、可能非常庞大的文本资料（例如，一篇长篇报告、一本电子书、一个复杂的网页或者大量的 API 文档）\n",
      "------------------------------ Chunk 2 ------------------------------\n",
      "网页或者大量的 API 文档）分割成一系列更小、更易于处理的文本片段（Chunks）的过程！这些 Chunks 是 RA\n",
      "------------------------------ Chunk 3 ------------------------------\n",
      "！这些 Chunks 是 RAG 系统中信息处理的基本单元。？\n",
      "------------------------------ Chunk 4 ------------------------------\n",
      "它们将被送入 Embedding 模型进行向量化，然后存入向量数据库进行索引，最终服务于检索环节。。\n",
      "。\n",
      "------------------------------ Chunk 5 ------------------------------\n",
      "这是一个新段落测试文本。哈哈哈！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recursive_character_text_splitter(text, chunk_size, chunk_overlap=0, separators=[\"\\n\\n\", \"\\n\", \"。\"]):\n",
    "    \"\"\"\n",
    "    手动实现 RecursiveCharacterTextSplitter 的功能\n",
    "    :param text: 要分割的文本\n",
    "    :param chunk_size: 每个文本块的最大长度\n",
    "    :param chunk_overlap: 相邻文本块的重叠长度\n",
    "    :param separators: 尝试分割文本的分隔符列表\n",
    "    :return: 分割后的文本块列表\n",
    "    \"\"\"\n",
    "    final_chunks = []\n",
    "    if not text:\n",
    "        return final_chunks\n",
    "    # 尝试按分隔符分割文本\n",
    "    separator = separators[0]\n",
    "    if separator:\n",
    "        splits = text.split(separator)\n",
    "    else:\n",
    "        splits = [text]\n",
    "    # 检查每个分割后的部分\n",
    "    good_splits = []\n",
    "    for split in splits:\n",
    "        # 分割后的文本长度小于 chunk_size，直接添加到 good_splits\n",
    "        # 如果分割后的文本长度大于 chunk_size，递归调用，使用下一个分隔符继续分割，知道分割后的文本长度小于 chunk_size 或者没有更多分隔符\n",
    "        # 最终 good_splits 中的每个元素都是长度小于 chunk_size 的文本\n",
    "        if len(split) < chunk_size:\n",
    "            good_splits.append(split)\n",
    "        else:\n",
    "            if len(separators) > 1:\n",
    "                # 递归调用，使用下一个分隔符\n",
    "                child_splits = recursive_character_text_splitter(split, chunk_size, chunk_overlap, separators[1:])\n",
    "                good_splits.extend(child_splits)\n",
    "            else:\n",
    "                # 如果没有更多分隔符，直接分割\n",
    "                for i in range(0, len(split), chunk_size - chunk_overlap):\n",
    "                    good_splits.append(split[i:i + chunk_size])\n",
    "    \n",
    "    # 合并相邻的分割部分，保证每个 chunk 的长度都不超过 chunk_size\n",
    "    for split in good_splits:\n",
    "        if not final_chunks:\n",
    "            final_chunks.append(split)\n",
    "        else:\n",
    "            last_chunk = final_chunks[-1]\n",
    "            if len(last_chunk) + len(split) <= chunk_size:\n",
    "                final_chunks[-1] = last_chunk + separator + split\n",
    "            else:\n",
    "                final_chunks.append(split)\n",
    "    return final_chunks\n",
    "\n",
    "\n",
    "# 测试数据\n",
    "text = \"\"\"文本分块（Text Chunking / Splitting）是什么？顾名思义，就是将原始的、可能非常庞大的文本资料\\\n",
    "（例如，一篇长篇报告、一本电子书、一个复杂的网页或者大量的 API 文档）分割成一系列更小、更易于处理的文本片段（Chunks）的过程！\\\n",
    "这些 Chunks 是 RAG 系统中信息处理的基本单元。它们将被送入 Embedding 模型进行向量化，然后存入向量数据库进行索引，最终服务于检索环节。\n",
    "这是一个新段落测试文本。哈哈哈！\"\"\"\n",
    "separators = ['\\n', '。', '？']\n",
    "\n",
    "# 测试\n",
    "# chunks = recursive_split(text, delimeter)\n",
    "chunks = recursive_character_text_splitter(text, 60, 15, separators)\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print('-'*30 + f' Chunk {idx} ' + '-'*30)\n",
    "    print(chunk)\n",
    "\n",
    "# 测试 RecursiveCharacterTextSplitter\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "# chunks = splitter.split_text(text)\n",
    "# for idx, chunk in enumerate(chunks):\n",
    "#     print('-'*30 + f' Chunk {idx} ' + '-'*30)\n",
    "#     print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 根据语义切分\n",
    "\n",
    "TODO:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
