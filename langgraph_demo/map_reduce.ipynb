{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:25:59.007662Z",
     "start_time": "2025-04-24T17:25:58.495328Z"
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from utils.env_util import *\n",
    "from langgraph_utils.common_util import gen_mermaid\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated\n",
    "from langgraph.types import Send\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:36:12.254003Z",
     "start_time": "2025-04-24T17:36:12.199792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ˆ OPENAI_API_KEY: sk-hybehtt*******************************lpkkvcvojw\n",
      "ğŸ‘€ DEFAULT_MODEL: Qwen/QwQ-32B\n",
      "ğŸ‘€ OPENAI_BASE_URL: https://api.siliconflow.cn/v1\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ Prompt\n",
    "subjects_prompt = \"\"\"åé¢çš„å¯¹è¯éƒ½ä½¿ç”¨ä¸­æ–‡æ¥å›ç­”ï¼Œéšæœºç”Ÿæˆ4ä¸ªä¸ {topic} ç›¸å…³çš„å…³é”®å­—ï¼Œæ³¨æ„åªè¦4ä¸ªï¼Œä¸è¦å¤šä¹Ÿä¸è¦å°‘ï¼Œä¸è¦é‡å¤ï¼Œç”Ÿæˆåä½ éœ€è¦è‡ªå·±æ£€æŸ¥ç»“æœæ˜¯å¦æ­£ç¡®ï¼Œç›´æ¥ç”Ÿæˆç»“æœä¸éœ€è¦å…¶ä»–æè¿°ã€‚\"\"\"\n",
    "joke_prompt = \"\"\"ç”Ÿæˆä¸€æ¡å…³äº {subject} çš„ç¬‘è¯ï¼Œä½¿ç”¨ä¸­æ–‡ï¼Œåªè¿”å›ä¸€è¡Œæ–‡å­—ï¼Œä¸è¦è¿”å›å¤šè¡Œã€‚æœ€åä½ éœ€è¦æ£€æŸ¥ç»“æœæ˜¯å¦æ»¡è¶³è¦æ±‚ï¼Œå¦‚æœæœ‰æ¢è¡Œç¬¦\\\\nä½ éœ€è¦å»é™¤æ¢è¡Œç¬¦\"\"\"\n",
    "best_joke_prompt = \"\"\"ä¸‹é¢æ˜¯4è¡Œæ˜¯4ä¸ªå…³äº {topic} çš„ç¬‘è¯ï¼ŒIDåˆ†åˆ«æ˜¯0ã€1ã€2ã€3ï¼Œé€‰æ‹©å…¶ä¸­ä¸€ä¸ªå¹¶è¿”å›å…¶IDï¼Œä¸è¦å¤šä½™çš„åˆ†ææˆ–æè¿°ï¼Œæœ€ç»ˆç»“æœåªè¦è¿”å›ä¸€ä¸ªå•è¡Œçš„intç±»å‹æ•°å­—ï¼Œä¸è¦åŒ…å«\\\\nç­‰ç‰¹æ®Šå­—ç¬¦ã€‚\n",
    "{jokes}\"\"\"\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int = Field(description=\"åºå·ï¼Œintç±»å‹ï¼Œå¦‚ï¼š1\", ge=0)\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=get_openai_api_key(),\n",
    "    model_name=get_default_model(),\n",
    "    # model_name=\"THUDM/GLM-Z1-32B-0414\",\n",
    "    base_url=get_openai_base_url(),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: Annotated[list, operator.add]\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str\n",
    "\n",
    "\n",
    "# ç¬‘è¯çš„ subject\n",
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "# é€šè¿‡ä¸€ä¸ª topic ç”Ÿæˆå¤šä¸ª subject\n",
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    print(f'ğŸ‘¨ {prompt}')\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    print(f\"âš™ï¸ç”Ÿæˆä¸»é¢˜ï¼š{response.subjects}\")\n",
    "    return {\"subjects\": response.subjects}\n",
    "\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    \"\"\"\n",
    "        è¿”å›ä¸€ä¸ª `Send` å¯¹è±¡åˆ—è¡¨\n",
    "        æ¯ä¸ª `Send` å¯¹è±¡ç”±å›¾ä¸­èŠ‚ç‚¹çš„åç§°ç»„æˆ\n",
    "        ä»¥åŠå‘é€åˆ°è¯¥èŠ‚ç‚¹çš„çŠ¶æ€\n",
    "\n",
    "        è¿™é‡Œæ˜¯æŠŠæ‰€æœ‰ç”Ÿæˆçš„ subject éƒ½å‘é€ç»™ `generate_joke` ç”Ÿæˆå¯¹åº”ä¸»é¢˜çš„ç¬‘è¯\n",
    "    \"\"\"\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]\n",
    "\n",
    "# ç”Ÿæˆä¸€æ¡ç¬‘è¯\n",
    "def generate_joke(joke: JokeState) -> OverallState:\n",
    "    subject = joke[\"subject\"]\n",
    "    prompt = joke_prompt.format(subject=subject)\n",
    "    response = model.with_structured_output(Joke).invoke(prompt)\n",
    "    print(f\"âš™ï¸ç”Ÿæˆ[{subject}]ç¬‘è¯ï¼š{response.joke}\")\n",
    "    return {\"jokes\": [response.joke]}\n",
    "\n",
    "def best_joke(state: OverallState) -> OverallState:\n",
    "    \"\"\"\n",
    "        ä»å¤šä¸ªç¬‘è¯ä¸­æ‰¾å‡º1ä¸ªæœ€å¥½çš„\n",
    "    \"\"\"\n",
    "    jokes = \"\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f'ğŸ‘¨ {prompt}')\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # response = model.with_structured_output(BestJoke).invoke(prompt)\n",
    "    response = model.invoke(prompt)\n",
    "    print(f\"âš™ï¸ é€‰æ‹©å‡ºäº†æœ€å¥½çš„ç¬‘è¯ï¼š{response}\")\n",
    "    idx = int(re.findall(r'\\d+', response.content)[0])\n",
    "    print(f\"âš™ï¸ ç¬‘è¯çš„IDæ˜¯ {idx}\")\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][idx]}\n",
    "\n",
    "\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_topics\", generate_topics)\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"best_joke\", best_joke)\n",
    "graph.add_edge(START, \"generate_topics\")\n",
    "graph.add_conditional_edges(\"generate_topics\", continue_to_jokes, [\"generate_joke\"])\n",
    "graph.add_edge(\"generate_joke\", \"best_joke\")\n",
    "graph.add_edge(\"best_joke\", END)\n",
    "app = graph.compile()\n",
    "\n",
    "# gen_mermaid(app, \"map_reduce.mmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:26:54.506846Z",
     "start_time": "2025-04-24T17:26:30.698442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¨ åé¢çš„å¯¹è¯éƒ½ä½¿ç”¨ä¸­æ–‡æ¥å›ç­”ï¼Œéšæœºç”Ÿæˆ4ä¸ªä¸ animal ç›¸å…³çš„å…³é”®å­—ï¼Œæ³¨æ„åªè¦4ä¸ªï¼Œä¸è¦å¤šä¹Ÿä¸è¦å°‘ï¼Œä¸è¦é‡å¤ï¼Œç”Ÿæˆåä½ éœ€è¦è‡ªå·±æ£€æŸ¥ç»“æœæ˜¯å¦æ­£ç¡®ï¼Œç›´æ¥ç”Ÿæˆç»“æœä¸éœ€è¦å…¶ä»–æè¿°ã€‚\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ç”Ÿæˆä¸»é¢˜ï¼š['ä¼é¹…', 'è´è¶', 'çŒè±¹', 'æµ·è±š']\n",
      "{'generate_topics': {'subjects': ['ä¼é¹…', 'è´è¶', 'çŒè±¹', 'æµ·è±š']}}\n",
      "âš™ï¸ç”Ÿæˆ[è´è¶]ç¬‘è¯ï¼šä¸ºä»€ä¹ˆè´è¶ä¸å–œæ¬¢ç©æ‰‘å…‹ç‰Œï¼Ÿå› ä¸ºå®ƒä»¬æ€•è¢«å‘ç°è—åœ¨ç¿…è†€ä¸‹çš„â€˜åƒâ€™ï¼\n",
      "{'generate_joke': {'jokes': ['ä¸ºä»€ä¹ˆè´è¶ä¸å–œæ¬¢ç©æ‰‘å…‹ç‰Œï¼Ÿå› ä¸ºå®ƒä»¬æ€•è¢«å‘ç°è—åœ¨ç¿…è†€ä¸‹çš„â€˜åƒâ€™ï¼']}}\n",
      "âš™ï¸ç”Ÿæˆ[ä¼é¹…]ç¬‘è¯ï¼šä¸ºä»€ä¹ˆä¼é¹…ä¸æ€•å†·ï¼Ÿå› ä¸ºå®ƒæœ‰æš–æš–çš„é±¼å¯äº²ï¼\n",
      "{'generate_joke': {'jokes': ['ä¸ºä»€ä¹ˆä¼é¹…ä¸æ€•å†·ï¼Ÿå› ä¸ºå®ƒæœ‰æš–æš–çš„é±¼å¯äº²ï¼']}}\n",
      "âš™ï¸ç”Ÿæˆ[æµ·è±š]ç¬‘è¯ï¼šæµ·è±šä¸ºä»€ä¹ˆå–œæ¬¢ç”¨é“¶è¡Œå¡ï¼Ÿå› ä¸ºå®ƒä»¬è§‰å¾—ç”¨å¡æ¯”ç”¨é±¼å¡æ›´æ–¹ä¾¿ï¼\n",
      "{'generate_joke': {'jokes': ['æµ·è±šä¸ºä»€ä¹ˆå–œæ¬¢ç”¨é“¶è¡Œå¡ï¼Ÿå› ä¸ºå®ƒä»¬è§‰å¾—ç”¨å¡æ¯”ç”¨é±¼å¡æ›´æ–¹ä¾¿ï¼']}}\n",
      "âš™ï¸ç”Ÿæˆ[çŒè±¹]ç¬‘è¯ï¼šçŒè±¹å»é¢è¯•ï¼Œè€ƒå®˜é—®å®ƒè·‘å¾—æœ€å¿«æ€ä¹ˆè¿˜å¤±ä¸šï¼Œå®ƒå›ç­”ï¼š'å› ä¸ºæ¯æ¬¡é¢è¯•å‰æˆ‘éƒ½åœ¨å†²åˆºï¼Œç»“æœæ€»æ˜¯è¢«è‡ªå·±çš„é€Ÿåº¦ç”©åœ¨åé¢ã€‚'\n",
      "{'generate_joke': {'jokes': [\"çŒè±¹å»é¢è¯•ï¼Œè€ƒå®˜é—®å®ƒè·‘å¾—æœ€å¿«æ€ä¹ˆè¿˜å¤±ä¸šï¼Œå®ƒå›ç­”ï¼š'å› ä¸ºæ¯æ¬¡é¢è¯•å‰æˆ‘éƒ½åœ¨å†²åˆºï¼Œç»“æœæ€»æ˜¯è¢«è‡ªå·±çš„é€Ÿåº¦ç”©åœ¨åé¢ã€‚'\"]}}\n",
      "================================================================================\n",
      "ğŸ‘¨ ä¸‹é¢æ˜¯4è¡Œæ˜¯4ä¸ªå…³äº animal çš„ç¬‘è¯ï¼ŒIDåˆ†åˆ«æ˜¯0ã€1ã€2ã€3ï¼Œé€‰æ‹©å…¶ä¸­ä¸€ä¸ªå¹¶è¿”å›å…¶IDï¼Œä¸è¦å¤šä½™çš„åˆ†ææˆ–æè¿°ï¼Œæœ€ç»ˆç»“æœåªè¦è¿”å›ä¸€ä¸ªå•è¡Œçš„intç±»å‹æ•°å­—ï¼Œä¸è¦åŒ…å«\\nç­‰ç‰¹æ®Šå­—ç¬¦ã€‚\n",
      "ä¸ºä»€ä¹ˆä¼é¹…ä¸æ€•å†·ï¼Ÿå› ä¸ºå®ƒæœ‰æš–æš–çš„é±¼å¯äº²ï¼\n",
      "ä¸ºä»€ä¹ˆè´è¶ä¸å–œæ¬¢ç©æ‰‘å…‹ç‰Œï¼Ÿå› ä¸ºå®ƒä»¬æ€•è¢«å‘ç°è—åœ¨ç¿…è†€ä¸‹çš„â€˜åƒâ€™ï¼\n",
      "çŒè±¹å»é¢è¯•ï¼Œè€ƒå®˜é—®å®ƒè·‘å¾—æœ€å¿«æ€ä¹ˆè¿˜å¤±ä¸šï¼Œå®ƒå›ç­”ï¼š'å› ä¸ºæ¯æ¬¡é¢è¯•å‰æˆ‘éƒ½åœ¨å†²åˆºï¼Œç»“æœæ€»æ˜¯è¢«è‡ªå·±çš„é€Ÿåº¦ç”©åœ¨åé¢ã€‚'\n",
      "æµ·è±šä¸ºä»€ä¹ˆå–œæ¬¢ç”¨é“¶è¡Œå¡ï¼Ÿå› ä¸ºå®ƒä»¬è§‰å¾—ç”¨å¡æ¯”ç”¨é±¼å¡æ›´æ–¹ä¾¿ï¼\n",
      "================================================================================\n",
      "âš™ï¸ é€‰æ‹©å‡ºäº†æœ€å¥½çš„ç¬‘è¯ï¼šcontent='\\n\\n2' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1194, 'prompt_tokens': 157, 'total_tokens': 1351, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 1192, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/QwQ-32B', 'system_fingerprint': '', 'id': '01966ac0845a35d8aaeef822d1dacb04', 'finish_reason': 'stop', 'logprobs': None} id='run-88d50a57-0c76-4018-a581-9a32be373bd6-0' usage_metadata={'input_tokens': 157, 'output_tokens': 1194, 'total_tokens': 1351, 'input_token_details': {}, 'output_token_details': {'reasoning': 1192}}\n",
      "âš™ï¸ ç¬‘è¯çš„IDæ˜¯ 2\n",
      "{'best_joke': {'best_selected_joke': \"çŒè±¹å»é¢è¯•ï¼Œè€ƒå®˜é—®å®ƒè·‘å¾—æœ€å¿«æ€ä¹ˆè¿˜å¤±ä¸šï¼Œå®ƒå›ç­”ï¼š'å› ä¸ºæ¯æ¬¡é¢è¯•å‰æˆ‘éƒ½åœ¨å†²åˆºï¼Œç»“æœæ€»æ˜¯è¢«è‡ªå·±çš„é€Ÿåº¦ç”©åœ¨åé¢ã€‚'\"}}\n"
     ]
    }
   ],
   "source": [
    "for s in app.stream({\"topic\": \"animal\"}, stream_mode=\"updates\"):\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
