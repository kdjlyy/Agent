{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在多 Agent 应用程序中添加多轮对话\n",
    "我们将创建 2 个智能体：\n",
    "- travel_advisor：可以提供旅行目的地推荐。可以向 hotel_advisor 寻求帮助。\n",
    "- hotel_advisor：可以提供酒店推荐。可以向 travel_advisor 寻求帮助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from utils.env_util import *\n",
    "from langgraph_utils.common_util import gen_mermaid\n",
    "import random\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.tools.base import InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent, InjectedState\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_travel_recommendations():\n",
    "    \"\"\"Get recommendation for travel destinations\"\"\"\n",
    "    return random.choice([\"aruba\", \"turks and caicos\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_hotel_recommendations(location: Literal[\"aruba\", \"turks and caicos\"]):\n",
    "    \"\"\"Get hotel recommendations for a given destination.\"\"\"\n",
    "    return {\n",
    "        \"aruba\": [\n",
    "            \"The Ritz-Carlton, Aruba (Palm Beach)\"\n",
    "            \"Bucuti & Tara Beach Resort (Eagle Beach)\"\n",
    "        ],\n",
    "        \"turks and caicos\": [\"Grace Bay Club\", \"COMO Parrot Cay\"],\n",
    "    }[location]\n",
    "\n",
    "\n",
    "def make_handoff_tool(*, agent_name: str):\n",
    "    \"\"\" 用于创建一个特殊的工具（tool），该工具允许一个代理（agent）将控制权转移（handoff）给另一个代理 \"\"\"\n",
    "\n",
    "    tool_name = f\"transfer_to_{agent_name}\"\n",
    "\n",
    "    # 工具的名称动态生成，格式为 transfer_to_{agent_name}，例如 transfer_to_agent2\n",
    "    @tool(tool_name, description=\"Create a tool that can return handoff via a Command\")\n",
    "    def handoff_to_agent(\n",
    "        # InjectedState：管理工具调用过程中的动态上下文，适合跨步骤数据共享。\n",
    "        state: Annotated[dict, InjectedState],\n",
    "        # InjectedToolCallId：唯一标识工具调用，用于跟踪和匹配异步操作。\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ):\n",
    "        # 创建一个工具消息（tool_message），内容为“成功切换到 {agent_name}”，表示控制权已成功转移。\n",
    "        # 返回一个 Command 对象，用于导航到目标代理节点 \"\"\"\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"成功切换到 {agent_name}\",\n",
    "            \"name\": tool_name,\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "\n",
    "        # goto=agent_name: 指定要转移到的目标代理名称。\n",
    "        # graph=Command.PARENT: 表示在父图中进行导航（即多代理对话的顶层图）。\n",
    "        # update: 更新目标代理的状态。这里将当前代理的消息历史（state[\"messages\"]）与工具消息（tool_message）合并，确保聊天记录完整有效。\n",
    "        return Command(\n",
    "            goto=agent_name,\n",
    "            graph=Command.PARENT,\n",
    "            update={\"messages\": state[\"messages\"] + [tool_message]},\n",
    "        )\n",
    "\n",
    "    return handoff_to_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙈 OPENAI_API_KEY: 5ca39a6a-d****************7dfa221f3f\n",
      "👀 DEFAULT_MODEL: doubao-1-5-thinking-pro-250415\n",
      "👀 OPENAI_BASE_URL: https://ark.cn-beijing.volces.com/api/v3\n",
      "✏️ 已生成 mermaid 文件 /workspace/Agent/langgraph_demo/resources/multi_agent_multi_turn_convo.mmd\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    openai_api_key=get_openai_api_key(),\n",
    "    model_name=get_default_model(),\n",
    "    # model_name='THUDM/GLM-Z1-32B-0414',\n",
    "    base_url=get_openai_base_url(),\n",
    ")\n",
    "\n",
    "# Define travel advisor tools and ReAct agent\n",
    "travel_advisor_tools = [\n",
    "    get_travel_recommendations,\n",
    "    make_handoff_tool(agent_name=\"hotel_advisor\"),\n",
    "]\n",
    "travel_advisor = create_react_agent(\n",
    "    model,\n",
    "    travel_advisor_tools,\n",
    "    prompt=(\n",
    "        \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc). \"\n",
    "        \"If you need hotel recommendations, ask 'hotel_advisor' for help. \"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_travel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"hotel_advisor\", \"human\"]]:\n",
    "    # You can also add additional logic like changing the input to the agent / output from the agent, etc.\n",
    "    # NOTE: we're invoking the ReAct agent with the full history of messages in the state\n",
    "    response = travel_advisor.invoke(state)\n",
    "    return Command(update=response, goto=\"human\")\n",
    "\n",
    "# Define hotel advisor tools and ReAct agent\n",
    "hotel_advisor = create_react_agent(\n",
    "    model = model,\n",
    "    tools = [get_hotel_recommendations, make_handoff_tool(agent_name=\"travel_advisor\")],\n",
    "    prompt=(\n",
    "        \"You are a hotel expert that can provide hotel recommendations for a given destination. \"\n",
    "        \"If you need help picking travel destinations, ask 'travel_advisor' for help.\"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_hotel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"travel_advisor\", \"human\"]]:\n",
    "    response = hotel_advisor.invoke(state)\n",
    "    return Command(update=response, goto=\"human\")\n",
    "\n",
    "\n",
    "def human_node(\n",
    "    state: MessagesState, config\n",
    ") -> Command[Literal[\"hotel_advisor\", \"travel_advisor\", \"human\"]]:\n",
    "\n",
    "    user_input = interrupt(value=\"Ready for user input.\")\n",
    "\n",
    "    # identify the last active agent\n",
    "    # (the last active node before returning to human)\n",
    "    langgraph_triggers = config[\"metadata\"][\"langgraph_triggers\"]\n",
    "    print(langgraph_triggers)\n",
    "    if len(langgraph_triggers) != 1:\n",
    "        raise AssertionError(\"Expected exactly 1 trigger in human node\")\n",
    "\n",
    "    active_agent = langgraph_triggers[0].split(\":\")[1]\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"human\",\n",
    "                    \"content\": user_input,\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        goto=active_agent,\n",
    "    )\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"travel_advisor\", call_travel_advisor)\n",
    "builder.add_node(\"hotel_advisor\", call_hotel_advisor)\n",
    "\n",
    "# This adds a node to collect human input, which will route\n",
    "# back to the active agent.\n",
    "builder.add_node(\"human\", human_node)\n",
    "\n",
    "# We'll always start with a general travel advisor.\n",
    "builder.add_edge(START, \"travel_advisor\")\n",
    "\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "gen_mermaid(graph, \"multi_agent_multi_turn_convo.mmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Conversation Turn 1 ---\n",
      "\n",
      "User: {'messages': [{'role': 'user', 'content': 'i wanna go somewhere warm in the caribbean'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel_advisor: \n",
      "\n",
      "在特克斯和凯科斯群岛，为您推荐以下优质酒店：\n",
      "\n",
      "1. **Grace Bay Club**：坐落在著名的格雷斯湾（Grace Bay）海滩旁，这里以细腻的白沙滩和清澈的 turquoise 海水闻名。酒店提供私人别墅和套房，配备完善的设施，适合家庭或情侣度假，周边还有丰富的水上活动可选。\n",
      "\n",
      "2. **COMO Parrot Cay**：一个高端私密的度假村，位于帕罗特凯岛（Parrot Cay），主打宁静与自然。酒店设计融合了现代与热带风格，提供水疗、瑜伽课程以及定制化的餐饮体验，是追求放松和奢华的理想之选。\n",
      "\n",
      "如果需要更详细的酒店信息（如价格、设施或用户评价），可以告诉我，我会尽力为您补充！\n",
      "('human',)\n",
      "\n",
      "--- Conversation Turn 2 ---\n",
      "\n",
      "User: Command(resume='could you recommend a nice hotel in one of the areas and tell me which area it is.')\n",
      "\n",
      "('branch:to:human',)\n",
      "()\n",
      "\n",
      "--- Conversation Turn 3 ---\n",
      "\n",
      "User: Command(resume='i like the first one. could you recommend something to do near the hotel?')\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "\n",
    "inputs = [\n",
    "    # 1st round of conversation,\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"i wanna go somewhere warm in the caribbean\"}\n",
    "        ]\n",
    "    },\n",
    "    # Since we're using `interrupt`, we'll need to resume using the Command primitive.\n",
    "    # 2nd round of conversation,\n",
    "    Command(\n",
    "        resume=\"could you recommend a nice hotel in one of the areas and tell me which area it is.\"\n",
    "    ),\n",
    "    # 3rd round of conversation,\n",
    "    Command(\n",
    "        resume=\"i like the first one. could you recommend something to do near the hotel?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "for idx, user_input in enumerate(inputs):\n",
    "    print()\n",
    "    print(f\"--- Conversation Turn {idx + 1} ---\")\n",
    "    print()\n",
    "    print(f\"User: {user_input}\")\n",
    "    print()\n",
    "    for update in graph.stream(user_input, config=thread_config, stream_mode=\"updates\"):\n",
    "        for node_id, value in update.items():\n",
    "            if isinstance(value, dict) and value.get(\"messages\", []):\n",
    "                last_message = value[\"messages\"][-1]\n",
    "                if isinstance(last_message, dict) or last_message.type != \"ai\":\n",
    "                    continue\n",
    "                print(f\"{node_id}: {last_message.content}\")\n",
    "    # print(graph.get_state(thread_config).next)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
