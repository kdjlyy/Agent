{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from utils.env_util import *\n",
    "from tools.search import bocha_websearch_tool\n",
    "from langgraph_utils.common_util import gen_mermaid\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Literal\n",
    "from langgraph.types import Send\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ„é€  code agnet node å’Œ research agent node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ˆ OPENAI_API_KEY: sk-hybehtt*******************************lpkkvcvojw\n",
      "ğŸ‘€ OPENAI_BASE_URL: https://api.siliconflow.cn/v1\n"
     ]
    }
   ],
   "source": [
    "class State(MessagesState):\n",
    "    next: str\n",
    "    \n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=get_openai_api_key(),\n",
    "    # model_name=get_default_model(),\n",
    "    model_name=\"deepseek-ai/DeepSeek-V3\",\n",
    "    base_url=get_openai_base_url(),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return result_str\n",
    "\n",
    "\n",
    "# NOTE: è¿™å°†æ‰§è¡Œä»»æ„ä»£ç ï¼Œå¦‚æœæ²¡æœ‰è¿›è¡Œæ²™ç›’å¤„ç†ï¼Œè¿™å¯èƒ½æ˜¯ä¸å®‰å…¨çš„\n",
    "code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "\n",
    "\n",
    "def code_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = code_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    llm, tools=[bocha_websearch_tool], prompt=\"You are a researcher. DO NOT do any math calculation.\"\n",
    ")\n",
    "\n",
    "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = research_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ›å»ºç›‘ç£è€… Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"researcher\", \"coder\"]\n",
    "# ç›‘ç£è€…æ˜¯LLMèŠ‚ç‚¹ï¼Œå®ƒé€‰æ‹©ä¸‹ä¸€ä¸ªagentæ¥å¤„ç†å’Œæ§åˆ¶ä½•æ—¶ç»ˆæ­¢\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ„å»ºå›¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœï¸ å·²ç”Ÿæˆ mermaid æ–‡ä»¶ /workspace/Agent/langgraph_demo/resources/multi_agent_supervisor.mmd\n",
      "                    +-----------+                     \n",
      "                    | __start__ |                     \n",
      "                    +-----------+                     \n",
      "                           *                          \n",
      "                           *                          \n",
      "                           *                          \n",
      "                    +------------+                    \n",
      "                    | supervisor |                    \n",
      "                   .+------------+.                   \n",
      "               ....        .       ....               \n",
      "            ...            .           ...            \n",
      "          ..               .              ..          \n",
      "+------------+         +-------+         +---------+  \n",
      "| researcher |         | coder |         | __end__ |  \n",
      "+------------+         +-------+         +---------+  \n"
     ]
    }
   ],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"researcher\", research_node)\n",
    "builder.add_node(\"coder\", code_node)\n",
    "graph = builder.compile()\n",
    "\n",
    "gen_mermaid(graph=graph, file_name=\"multi_agent_supervisor.mmd\")\n",
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è°ƒç”¨å¤š Agent ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((), {'supervisor': {'next': 'researcher'}})\n",
      "----\n",
      "(('researcher:944ad962-dc99-429e-245f-faa9ece3e1e2',), {'agent': {'messages': [AIMessage(content='è¦å›ç­”â€œåŒ—äº¬åˆ°ä¸Šæµ·çš„è·ç¦»â€è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘éœ€è¦å…ˆæœç´¢ç›¸å…³çš„ä¿¡æ¯ã€‚ç”±äºè¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„åœ°ç†é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ç½‘ç»œæœç´¢è·å–å‡†ç¡®çš„æ•°æ®ã€‚æˆ‘å°†ä½¿ç”¨ç½‘é¡µæœç´¢å·¥å…·æ¥æŸ¥æ‰¾åŒ—äº¬åˆ°ä¸Šæµ·çš„ç›´çº¿è·ç¦»æˆ–å®é™…äº¤é€šè·ç¦»ã€‚\\n\\n', additional_kwargs={'tool_calls': [{'id': '01966b0eacbac94ad3c4d8db0d6d2b0a', 'function': {'arguments': '{\"query\":\"åŒ—äº¬åˆ°ä¸Šæµ·çš„è·ç¦»\",\"count\":1}', 'name': 'bocha_websearch_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 256, 'total_tokens': 332, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '01966b0e8b7756e33a7a829fce61d2dc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-066235a8-a8fa-4774-92e8-4ec8643a0736-0', tool_calls=[{'name': 'bocha_websearch_tool', 'args': {'query': 'åŒ—äº¬åˆ°ä¸Šæµ·çš„è·ç¦»', 'count': 1}, 'id': '01966b0eacbac94ad3c4d8db0d6d2b0a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 76, 'total_tokens': 332, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})]}})\n",
      "----\n",
      "âœ”ï¸ OPENAI_API_KEY: sk-hybehttizlquaobtbilikijqmuuyzxizjhkfqqlpkkvcvojw\n",
      "âœ”ï¸ OPENAI_BASE_URL: https://api.siliconflow.cn/v1\n",
      "âœ”ï¸ AVAILABLE_MODELS: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B,THUDM/GLM-Z1-32B-0414,Qwen/Qwen2.5-VL-32B-Instruct,Qwen/QwQ-32B,THUDM/GLM-Z1-32B-0414,deepseek-ai/DeepSeek-V3,deepseek-ai/DeepSeek-R1\n",
      "âœ”ï¸ BOCHA_API_KEY: sk-b71f4859decc427e99f7b0e3fa483469\n",
      "(('researcher:944ad962-dc99-429e-245f-faa9ece3e1e2',), {'tools': {'messages': [ToolMessage(content='å¼•ç”¨: 1\\næ ‡é¢˜: ä»åŒ—äº¬åˆ°ä¸Šæµ·æœ‰å¤šè¿œ_æ‡‚è§†\\nURL: https://www.51dongshi.com/esgedfrcreabvcr.html\\næ‘˜è¦: ä»åŒ—äº¬åˆ°ä¸Šæµ·å…¨ç¨‹çº¦1213.8å…¬é‡Œ,è‡ªé©¾è€—æ—¶14å°æ—¶52åˆ†é’Ÿ,é€”ç»:é•¿æ·±é«˜é€Ÿï½¤æ²ˆæµ·é«˜é€Ÿï½¡åŒ—äº¬æ˜¯ä¸­å›½â€œå…«å¤§å¤éƒ½â€ä¹‹ä¸€,æ‹¥æœ‰7é¡¹ä¸–ç•Œé—äº§,æ˜¯ä¸–ç•Œä¸Šæ‹¥æœ‰ä¸–ç•Œæ–‡åŒ–é—äº§æ•°æœ€å¤šçš„åŸå¸‚,ä¼—å¤šåèƒœå¤è¿¹å’Œäººæ–‡æ™¯è§‚ä¸è®¡å…¶æ•°ï½¤ä¸èƒœæšä¸¾ï½¡å…«è¾¾å²­é•¿åŸæ—…æ¸¸åŒºï½¤åŒ—äº¬ç¯çƒåº¦å‡åŒºï½¤æ•…å®«åšç‰©é™¢ï½¤é¢å’Œå›­ï½¤åŒ—äº¬æ¬¢ä¹è°·ï½¤åŒ—äº¬åŠ¨ç‰©å›­ï½¤åŒ—äº¬å¥¥æ—åŒ¹å…‹å…¬å›­.....\\nç½‘ç«™åç§°: æ‡‚è§†ç”Ÿæ´»\\nå‘å¸ƒæ—¶é—´: 2024-08-30T20:02:32Z', name='bocha_websearch_tool', id='b1954fcb-fa93-4a1c-93e5-97ffbae43df5', tool_call_id='01966b0eacbac94ad3c4d8db0d6d2b0a')]}})\n",
      "----\n",
      "(('researcher:944ad962-dc99-429e-245f-faa9ece3e1e2',), {'agent': {'messages': [AIMessage(content='åŒ—äº¬åˆ°ä¸Šæµ·çš„ç›´çº¿è·ç¦»çº¦ä¸º1213.8å…¬é‡Œï¼Œå¦‚æœè‡ªé©¾çš„è¯ï¼Œå¤§çº¦éœ€è¦14å°æ—¶52åˆ†é’Ÿï¼Œé€”ç»é•¿æ·±é«˜é€Ÿå’Œæ²ˆæµ·é«˜é€Ÿã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 534, 'total_tokens': 566, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '01966b0eb19222056c9ea0088c498835', 'finish_reason': 'stop', 'logprobs': None}, id='run-922da881-0af7-4a77-8f96-68c88e769ae9-0', usage_metadata={'input_tokens': 534, 'output_tokens': 32, 'total_tokens': 566, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})]}})\n",
      "----\n",
      "((), {'researcher': {'messages': [HumanMessage(content='åŒ—äº¬åˆ°ä¸Šæµ·çš„ç›´çº¿è·ç¦»çº¦ä¸º1213.8å…¬é‡Œï¼Œå¦‚æœè‡ªé©¾çš„è¯ï¼Œå¤§çº¦éœ€è¦14å°æ—¶52åˆ†é’Ÿï¼Œé€”ç»é•¿æ·±é«˜é€Ÿå’Œæ²ˆæµ·é«˜é€Ÿã€‚', additional_kwargs={}, response_metadata={}, name='researcher')]}})\n",
      "----\n",
      "((), {'supervisor': {'next': '__end__'}})\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"åŒ—äº¬åˆ°ä¸Šæµ·çš„è·ç¦»\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    subgraphs=True,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((), {'supervisor': {'next': 'coder'}})\n",
      "********************************************************************************\n",
      "(('coder:6f46a5ef-5266-eadf-14ae-503627ff1c7b',), {'agent': {'messages': [AIMessage(content=\"To find the answer to 1 + 4, I can use simple arithmetic. The sum of 1 and 4 is straightforward, but I'll verify it using the Python REPL tool to ensure accuracy.\", additional_kwargs={'tool_calls': [{'id': '01966b0f12065d41d3b5ae304ab2fb70', 'function': {'arguments': '{\"code\":\"print(1 + 4)\"}', 'name': 'python_repl_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 211, 'total_tokens': 281, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '01966b0ef1136b6c3b53aadd8ab7e933', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-856b484f-392b-4017-8073-9c8f1061421d-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(1 + 4)'}, 'id': '01966b0f12065d41d3b5ae304ab2fb70', 'type': 'tool_call'}], usage_metadata={'input_tokens': 211, 'output_tokens': 70, 'total_tokens': 281, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})]}})\n",
      "********************************************************************************\n",
      "(('coder:6f46a5ef-5266-eadf-14ae-503627ff1c7b',), {'tools': {'messages': [ToolMessage(content='Successfully executed:\\n\\\\`\\\\`\\\\`python\\nprint(1 + 4)\\n\\\\`\\\\`\\\\`\\nStdout: 5\\n', name='python_repl_tool', id='236464f5-76a0-4906-9071-5d0fa1cba84a', tool_call_id='01966b0f12065d41d3b5ae304ab2fb70')]}})\n",
      "********************************************************************************\n",
      "(('coder:6f46a5ef-5266-eadf-14ae-503627ff1c7b',), {'agent': {'messages': [AIMessage(content='The answer to 1 + 4 is 5.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 318, 'total_tokens': 330, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '01966b0f1231a3448613207cebac4388', 'finish_reason': 'stop', 'logprobs': None}, id='run-10dcdd75-9702-4e24-b42d-d233f453bcdf-0', usage_metadata={'input_tokens': 318, 'output_tokens': 12, 'total_tokens': 330, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})]}})\n",
      "********************************************************************************\n",
      "((), {'coder': {'messages': [HumanMessage(content='The answer to 1 + 4 is 5.', additional_kwargs={}, response_metadata={}, name='coder')]}})\n",
      "********************************************************************************\n",
      "((), {'supervisor': {'next': '__end__'}})\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What's the answer of 1+4?\")]}, subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"*\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
