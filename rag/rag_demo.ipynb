{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(filename, page_number=None, min_line_length=1):\n",
    "    \"\"\"Extract text from a PDF file.\n",
    "    Args:\n",
    "        filename (str): Path to the PDF file.\n",
    "        page_number (int, optional): Page number to extract. If None, extracts all pages.\n",
    "        min_line_length (int, optional): Minimum length of a line to be included in the output.\n",
    "    Returns:\n",
    "        str: Extracted text.\n",
    "    \"\"\"\n",
    "    paragraphs = []\n",
    "    buffer, full_text = '', ''\n",
    "    # 提取全部文本\n",
    "    for i, page_layout in enumerate(extract_pages(filename)):\n",
    "        if page_number is not None and i != page_number:\n",
    "            continue\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                full_text += element.get_text() + '\\n'\n",
    "    # 按空行分隔，将文本重新组织成段落\n",
    "    for line in full_text.split('\\n'):\n",
    "        if len(line) >= min_line_length:\n",
    "            buffer += (' ' + line) if not line.endswith('-') else line.strip('-')\n",
    "        elif buffer:\n",
    "            paragraphs.append(buffer.strip())\n",
    "            buffer = ''\n",
    "    if buffer:\n",
    "        paragraphs.append(buffer.strip())\n",
    "    return paragraphs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeetCode 101: A Grinding Guide (Second Edition)\n",
      "\n",
      "版本：正式版 2.0c，最新版见 GitHub changgyhub/leetcode_101\n",
      "\n",
      "一个面向有一定的编程基础，但缺乏刷题经验的读者的教科书和工具书。\n",
      "\n",
      "2019 年底，本书第一版在 GitHub 上正式发布，反响十分热烈。过去的五年，作者积累了大\n",
      "\n",
      "量的工作经验，同时也越来越觉得这本书存在很多纰漏和不完善之处。于是在 2024 年底，作者\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paragraphs = extract_text_from_pdf(\"file/LeetCode 101 - A Grinding Guide.pdf\", min_line_length=30)\n",
    "for paragraph in paragraphs[:5]:\n",
    "    print(paragraph + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\n你好！我是通义千问，阿里巴巴集团旗下的超大规模语言模型。我能够回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。我熟练掌握多种语言，包括但不限于中文、英文、德语、法语、西班牙语等。\\n\\n如果你有任何问题或需要帮助，随时告诉我！😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 290, 'prompt_tokens': 12, 'total_tokens': 302, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 205, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_name': 'Qwen/QwQ-32B', 'system_fingerprint': '', 'id': '01968030c05b25b7cb43503f7be9c1f6', 'finish_reason': None, 'logprobs': None}, id='run-67e9c66e-e3e6-4043-9932-d14203a02193-0', usage_metadata={'input_tokens': 12, 'output_tokens': 290, 'total_tokens': 302, 'input_token_details': {}, 'output_token_details': {'reasoning': 205}})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.env_util import *\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_completion(prompt):\n",
    "    message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    model = ChatOpenAI(\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        model_name=os.getenv(\"MODEL_NAME\"),\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return model.invoke(message)\n",
    "\n",
    "get_completion(\"你是谁\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "你是一个问答机器人，你的任务是根据下述给定的已知信息回答用户问题。如果你不知道答案，就回答不知道，不要胡编乱造。\n",
    "\n",
    "已知信息：\n",
    "{context}\n",
    "\n",
    "用户问题：\n",
    "{query}\n",
    "\n",
    "如果已知信息不包含用户问题的答案，或者已知信息不足以回答用户的问题，就回答不知道，不要胡编乱造。\n",
    "请不要输出已知信息中不包含的信息或答案。\n",
    "请用中文回答用户问题。\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt(prompt_template, **kwargs):\n",
    "    \"\"\"\n",
    "    自定义参数渲染 Prompt 模板\n",
    "    \"\"\"\n",
    "    inputs = {}\n",
    "    for k, v in kwargs.items():\n",
    "        if isinstance(v, list) and all(isinstance(elem, str) for elem in v):\n",
    "            val = \"\\n\\n\".join(v)\n",
    "        else:\n",
    "            val = v\n",
    "        inputs[k] = val\n",
    "    return prompt_template.format(**inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量间相似度的计算\n",
    "\n",
    "余弦相似度通过向量点积与模长乘积的比值计算，公式如下： \n",
    "\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} = \\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}}\n",
    "$$\n",
    "\n",
    "L2 距离是向量对应元素差的平方和的平方根，公式如下：\n",
    "\n",
    "$$\n",
    "d(\\mathbf{A}, \\mathbf{B}) = \\sqrt{\\sum_{i=1}^{n} (A_i - B_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    ''' 余弦相似度（越大越相似） '''\n",
    "    return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "def l2_distance(A, B):\n",
    "    ''' 欧式距离（越小越相似） '''\n",
    "    x = np.asarray(A)\n",
    "    y = np.asarray(B)\n",
    "    return norm(x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入模型\n",
    "\n",
    "[嵌入模型库](https://www.modelscope.cn/models?page=1&tasks=sentence-embedding&type=nlp)\n",
    "\n",
    "标准\n",
    "\n",
    "- **找需求相关的语料库来进行文本向量转换测试，进行评估**\n",
    "- 大多数场景下，开源的嵌入模型使用效果都一般，要进行检索召回率，建议对模型进行微调\n",
    "- 嵌入模型的维度越高，表示特征细节提取越丰富"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dimension: 1024\n",
      "Fist 10 Dimensions: [0.05262557417154312, 0.02764252945780754, 0.07897865772247314, -0.0029994763899594545, 0.0073790643364191055, 0.026514261960983276, 0.009670855477452278, -0.0016747706104069948, 0.045372430235147476, 0.004772466607391834]\n",
      "\n",
      "[ARK] Total Dimension: 4096\n",
      "[ARK] Fist 10 Dimensions: [0.2421875, 3.859375, -0.482421875, -3.96875, 0.74609375, -2.625, 1.6015625, 3.359375, 0.3984375, 3.25]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from volcenginesdkarkruntime import Ark\n",
    "\n",
    "def get_embeddings(texts: List[str]):\n",
    "    ''' OpenAI Embeddings '''\n",
    "    embedding_model = OpenAIEmbeddings(\n",
    "        api_key=os.getenv('OPENAI_API_KEY'),\n",
    "        base_url=os.getenv('OPENAI_BASE_URL'),\n",
    "        model=os.getenv('EMBEDDING_MODEL_NAME')\n",
    "    )\n",
    "    return embedding_model.embed_documents(texts)\n",
    "\n",
    "def get_ark_embeddings(texts: List[str]):\n",
    "    client = Ark(api_key=os.getenv('ARK_API_KEY'))\n",
    "    return client.embeddings.create(\n",
    "        model=\"doubao-embedding-large-text-240915\",\n",
    "        input=texts\n",
    "    )\n",
    "\n",
    "test_texts = ['吃完海鲜可以喝牛奶吗？']\n",
    "vec = get_embeddings(test_texts)[0]\n",
    "print(f'Total Dimension: {len(vec)}')\n",
    "print(f'Fist 10 Dimensions: {vec[:10]}')\n",
    "\n",
    "vec = get_ark_embeddings(test_texts).data[0].embedding\n",
    "print(f'\\n[ARK] Total Dimension: {len(vec)}')\n",
    "print(f'[ARK] Fist 10 Dimensions: {vec[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query 与自己的余弦距离为：1.0\n",
      "query 与文档的余弦距离为：\n",
      "0.8851309597447\n",
      "0.8601865743943213\n",
      "0.802517564858825\n",
      "0.7592321142985579\n",
      "0.796052817036916\n",
      "********************************************************************************\n",
      "query 与自己的L2距离为：0.0\n",
      "query 与文档的L2距离为：\n",
      "63.85760211053751\n",
      "69.9480541076191\n",
      "82.65289032621875\n",
      "91.29779700506289\n",
      "84.24111387780202\n"
     ]
    }
   ],
   "source": [
    "query = \"国际争端\"\n",
    "# 前两条为国际争端\n",
    "documents = [\n",
    "    \"联合国就苏丹达尔富地区大规模暴力事件发出警告\",\n",
    "    \"土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判\",\n",
    "    \"日本歧阜市陆上自卫队射击场内发生枪击事件 3人受伤\",\n",
    "    \"国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营\",\n",
    "    \"我国首次在空间站开展舱外辐射生物学暴露实验\"\n",
    "]\n",
    "\n",
    "# query_vector = get_embeddings([query])[0]\n",
    "# doc_vectors = get_embeddings(documents)\n",
    "\n",
    "# 实测 doubao Embedding 模型效果更好\n",
    "query_vector = get_ark_embeddings([query]).data[0].embedding\n",
    "doc_vectors = [doc_vector.embedding for doc_vector in get_ark_embeddings(documents).data]\n",
    "\n",
    "# 余弦距离越大表示越相似\n",
    "print(f'query 与自己的余弦距离为：{cosine_similarity(query_vector, query_vector)}')\n",
    "print('query 与文档的余弦距离为：')\n",
    "for doc_vector in doc_vectors:\n",
    "    print(f'{cosine_similarity(query_vector, doc_vector)}')\n",
    "\n",
    "print('*' * 80)\n",
    "\n",
    "# L2距离（欧式距离）越小表示越相似\n",
    "print(f'query 与自己的L2距离为：{l2_distance(query_vector, query_vector)}')\n",
    "print('query 与文档的L2距离为：')\n",
    "for doc_vector in doc_vectors:\n",
    "    print(f'{l2_distance(query_vector, doc_vector)}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
